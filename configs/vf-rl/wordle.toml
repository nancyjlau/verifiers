model = "Qwen/Qwen3-4B-Instruct-2507"

[env]
id = "wordle"

[inference]
gpus = 1

[trainer]
gpus = 1

[trainer.args]
lora_target_modules = "all-linear"
run_name = "wordle"
micro_batch_size = 4
rollouts_per_example = 16
batch_size = 512
max_steps = 500
max_seq_len = 2048
